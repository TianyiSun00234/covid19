{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import copy\nimport numpy as np\nimport pandas as pd\nimport scipy.optimize as opt\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nfrom datetime import datetime, timedelta\nfrom sklearn.metrics import mean_squared_log_error\nimport warnings; warnings.filterwarnings('ignore')\nfrom scipy.stats import pearsonr\nfrom scipy.optimize import curve_fit\nfrom scipy.optimize import least_squares\nfrom scipy import interpolate\nfrom scipy.signal import savgol_filter\nimport statsmodels.api as sm\nfrom pmdarima.arima import auto_arima\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load Data and parse datetime columns\ntrain = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv', parse_dates=['Date'])\ntest = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv', parse_dates=['Date'])\n\n# Pull in population data to help with model fitting\npopulations = pd.read_csv('/kaggle/input/covid19-global-forecasting-locations-population/locations_population.csv').iloc[:, :3]\npopulations.columns = ['Province_State', 'Country_Region', 'Population']\n\n# Replace the NaN values with a space\ntrain['Province_State'].fillna(\"\",inplace = True)\ntest['Province_State'].fillna(\"\",inplace = True)\npopulations['Province_State'].fillna(\"\",inplace = True)\n\n# Combine the Country_Rgion and Province_State columns into a single column\ntrain['Country_Region'] = train['Country_Region'] + ' ' + train['Province_State']\ntest['Country_Region'] = test['Country_Region'] + ' ' + test['Province_State']\npopulations['Country_Region'] = populations['Country_Region'] + ' ' + populations['Province_State']\n\n# Delete the Province_State column because it is accounted for elsewhere\ndel train['Province_State']\ndel test['Province_State']\ndel populations['Province_State']\nUnique_Regions = train['Country_Region'].unique()\n\n# Only use data up to 04/01 to get a public LB score\ncutoff_date = min(test['Date'])\neval_set = train[train[\"Date\"] >= cutoff_date]\nnumber_of_overlap_days = int(len(eval_set)/len(Unique_Regions))\ndays_to_predict = len(test['Date'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_feature_from_old(function):\n    feature_cases = train[train['ConfirmedCases']>=1]['ConfirmedCases'].map(function)\n    feature_fatalities = train['Fatalities'].map(function)\n    Features = copy.copy(train[train['ConfirmedCases']>=1])\n    Features['ConfirmedCases'] = feature_cases\n    Features['Fatalities'] = feature_fatalities\n    return Features\n\nFeature_0 = new_feature_from_old(lambda x: x) # lol\nFeature_1 = new_feature_from_old(lambda x: np.sqrt(x))\nFeature_2 = new_feature_from_old(lambda x: np.log(x + 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Validation Error"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Root mean squared logarithmic error\ndef RMSLE(pred,actual):\n    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Slice Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def slice_by_region_variable_leaderboard(region, variable_idx, leaderboard_flag, feature):\n    # variable_idx: 1 --> confirmed cases, 2 --> fatalities \n    # leaderboard: 0 --> only use data before cutoff, 1 --> include all data\n    \n    missing_flag = 0\n    if leaderboard_flag == 0:\n        df = copy.copy(feature[(feature['Country_Region']==region) & (feature['Date'] < cutoff_date)])\n    else:\n        df = copy.copy(feature[feature['Country_Region']==region])\n    \n    if region not in feature['Country_Region'].unique():\n        missing_flag = 1\n        endog = np.zeroes(days_to_predict)\n    \n    else:\n        if variable_idx == 1:\n            endog  = df['ConfirmedCases'].values\n        elif variable_idx == 2:\n            endog  = df['Fatalities'].values\n\n    return endog, missing_flag\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Arima Model - no transformation - Order selection with auto_arima"},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://stats.stackexchange.com/questions/313426/mle-convergence-errors-with-statespace-sarimax\ndef predict_0(region, variable_idx, leaderboard_flag):\n    # variable_idx: 1 --> confirmed cases, 2 --> fatalities \n    # leaderboard_flag: 0 --> use data on and before 04/01/2020 to train, otherwise --> use all data in the training set\n    \n#     if leaderboard_flag == 0:\n#         df = copy.copy(Features[(Features['Country_Region']==region) & (Features['Date'] < cutoff_date)])\n#     else:\n#         df = copy.copy(Features[Features['Country_Region']==region])\n    \n#     if region not in Features['Country_Region'].unique():\n#         forecast = np.zeros(43)\n    \n#     if variable_idx == 1:\n#         endog  = df['ConfirmedCases'].values\n#         #order=(1,1,4)\n#     elif variable_idx == 2:\n#         endog  = df['Fatalities'].values\n#         #order=(1,1,0)\n    endog, missing_flag = slice_by_region_variable_leaderboard(region, variable_idx, leaderboard_flag, Feature_0)        \n    \n    try:\n#         model = sm.tsa.statespace.SARIMAX(endog, order=order,\n#                         measurement_error=True, initialization='approximate_diffuse')\n        model = auto_arima(endog, trace=False, error_action='ignore', n_jobs=-1, maxiter=400, disp=-1, suppress_warnings=True)\n#        fitted_model = model.fit(maxiter=400, method='powell', disp=False)\n        model.fit(endog)\n#         print(model.summary())\n#        res = model.filter(fitted_model.params)\n        forecast = model.predict(n_periods=days_to_predict)\n    except:\n        forecast = np.zeros(days_to_predict)\n    return pd.Series(forecast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Arima Model with Square Root transform - Order selection with auto_arima"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_1(region, variable_idx, leaderboard_flag):\n    # variable_idx: 1 --> confirmed cases, 2 --> fatalities \n    # leaderboard_flag: 0 --> use data on and before 04/01/2020 to train, otherwise --> use all data in the training set\n    \n#     if leaderboard_flag == 0:\n#         df = copy.copy(Features_1[(Features_1['Country_Region']==region) & (Features_1['Date'] < cutoff_date)])\n#     else:\n#         df = copy.copy(Features_1[Features_1['Country_Region']==region])\n    \n#     if region not in Features['Country_Region'].unique():\n#         forecast = np.zeros(43)\n    \n#     if variable_idx == 1:\n#         endog  = df['ConfirmedCases'].values\n#         #order=(7,1,0)\n#     elif variable_idx == 2:\n#         endog  = df['Fatalities'].values\n#         #order=(1,1,0)\n    endog, missing_flag = slice_by_region_variable_leaderboard(region, variable_idx, leaderboard_flag, Feature_1)\n    \n    try:\n#         model = sm.tsa.statespace.SARIMAX(endog, order=order,\n#                         measurement_error=True, initialization='approximate_diffuse')\n        model = auto_arima(endog, trace=False, error_action='ignore', n_jobs=-1, maxiter=400, disp=-1, suppress_warnings=True)\n#         fitted_model = model.fit(disp=False)\n        model.fit(endog)\n#         res = model.filter(fitted_model.params)\n        forecast = model.predict(n_periods=days_to_predict)\n    except:\n        forecast = np.zeros(days_to_predict)\n    print(region)\n    return pd.Series(forecast).map(lambda x: x**2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Arima Model with Log Transform - Order selection with auto_arima"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_2(region, variable_idx, leaderboard_flag):\n    # variable_idx: 1 --> confirmed cases, 2 --> fatalities \n    # leaderboard_flag: 0 --> use data on and before 04/01/2020 to train, otherwise --> use all data in the training set\n    \n#     if leaderboard_flag == 0:\n#         df = copy.copy(Features_2[(Features_2['Country_Region']==region) & (Features_2['Date'] < cutoff_date)])\n#     else:\n#         df = copy.copy(Features_2[Features_2['Country_Region']==region])\n    \n#     if region not in Features['Country_Region'].unique():\n#         forecast = np.zeros(43)\n    \n#     if variable_idx == 1:\n#         endog  = df['ConfirmedCases'].values\n#         #order=(7,1,0)\n#     elif variable_idx == 2:\n#         endog  = df['Fatalities'].values\n#         #order=(1,1,0)\n    endog, missing_flag = slice_by_region_variable_leaderboard(region, variable_idx, leaderboard_flag, Feature_2)\n    \n    try:\n#         model = sm.tsa.statespace.SARIMAX(endog, order=order,\n#                         measurement_error=True, initialization='approximate_diffuse')\n        model = auto_arima(endog, trace=False, error_action='ignore', n_jobs=-1, maxiter=400, disp=-1, suppress_warnings=True)\n#         fitted_model = model.fit(disp=False)\n        model.fit(endog)\n#         res = model.filter(fitted_model.params)\n        forecast = model.predict(n_periods=days_to_predict)\n    except:\n        forecast = np.zeros(days_to_predict)\n    print(region)\n    return pd.Series(forecast).map(lambda x: np.exp(x) - 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Multi-Level Logistic Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def multi_level_logistic(x, t, y):\n    return x[0]/(1 + np.exp(-x[1] * (t - x[2]))) - y\n\ndef multi_level_logistic_model(x, t):\n    return x[0]/(1 + np.exp(-x[1] * (t - x[2])))\n\ndef guess_parameters(y, population, flag):\n    # flag=0 --> first pass, flag=1 --> correction\n    x = np.ones(3)\n    middle_loc = int(np.abs(y - y.max()/2).argmin())\n    perct_75_loc = int(np.abs(y - 3*y.max()/4).argmin())\n    try:\n        first_case_loc = np.where(y>1)[0][0]\n    except:\n        first_case_loc = -1\n    if flag==0:\n        x[0] = 1E-5*population\n        x[2] =int(middle_loc)-7\n    else:\n        x[0] = 1E-5*population\n        x[2] = first_case_loc + 21\n    try:\n        x[1] = 20/max(1, perct_75_loc - middle_loc) # estimation of rate of transmission\n    except:\n        x[1] = np.log(2)/2.\n    return x\n\n    \ndef fit_model(y_train, population, n):\n    t_train = range(len(y_train))\n    t_final = range(len(y_train), len(y_train) + n +1)\n    x0 = guess_parameters(y_train, population, 0)\n    res_robust_1 = least_squares(multi_level_logistic, x0, loss='soft_l1', f_scale=0.1, args=(t_train, y_train))\n    fit_1 = multi_level_logistic_model(res_robust_1.x, t_train)\n    residual = y_train - fit_1\n    x0 = guess_parameters(residual, population, 1)\n    res_robust_2 = least_squares(multi_level_logistic, x0, loss='cauchy', f_scale=0.1, args=(t_train, residual))\n    fit_2 = multi_level_logistic_model(res_robust_2.x, t_train)\n    final_forecast = multi_level_logistic_model(res_robust_1.x, t_final) + multi_level_logistic_model(res_robust_2.x, t_final)\n    return final_forecast\n\ndef predict_3(region, variable_idx, leaderboard_flag):\n    # region is a list of the Province_State and Country_Region\n    # variable_idx: 1 --> cases, 2 --> fatalities\n    # leaderboard_flag: 0 --> public (30 days), 1 --> private (43 days)\n    \n    if leaderboard_flag == 0:\n        df = copy.copy(train[(train[\"Date\"] < cutoff_date) & (train['Country_Region'] == region)])\n        n = days_to_predict - number_of_overlap_days\n    else:\n        df = copy.copy(train[train['Country_Region'] == region])\n        n = days_to_predict\n    ydata = df.iloc[:, variable_idx + 2].values\n    ynew = savgol_filter(ydata, 5, 3)\n    xdata = range(len(ydata))\n    t_final = range(len(ydata), len(ydata) + n)\n    population = populations[populations['Country_Region'] == region].iloc[0,1]\n    forecast = fit_model(ydata, population, n-1)\n    if leaderboard_flag == 0:\n        forecast = np.concatenate([ydata[-number_of_overlap_days:], forecast])\n    return forecast","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Fill Forward Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_4(region, variable_idx, leaderboard_flag):\n    \n    if variable_idx == 1:\n        temp = train[train['Country_Region']==region]['ConfirmedCases'].values\n    else:\n        temp = train[train['Country_Region']==region]['Fatalities'].values\n        \n    if leaderboard_flag == 0:\n        value =temp[-18]\n    else:\n        value = temp[-1]\n        \n    return np.ones(43)*value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing Logistic Model Fit"},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_set[eval_set['Country_Region']==Unique_Regions[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,10):\n    t = range(0, 43)\n    t2 = range(0, number_of_overlap_days)\n    t2 = range(-number_of_overlap_days, 0)\n    plt.plot(t, predict_0(Unique_Regions[i], 1, 1), label='Arima no transf')\n    plt.plot(t, predict_1(Unique_Regions[i], 1, 1), label='Arima sqrt')\n   # plt.plot(t, predict_2(Unique_Regions[i], 1, 1), label='Arima log')\n    plt.plot(t, predict_3(Unique_Regions[i], 1, 1), label='Logistic')\n    plt.plot(t, predict_4(Unique_Regions[i], 1, 1), label='Forward Fill')\n    plt.plot(t2, eval_set[eval_set['Country_Region']==Unique_Regions[i]]['ConfirmedCases'].values, label='Eval Data')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_idxs_confirmed = []\nmodel_idxs_fatalities = []\nfor region in Unique_Regions:\n    actual_confirmed = eval_set[eval_set['Country_Region']==region]['ConfirmedCases'].values\n    actual_fatalities = eval_set[eval_set['Country_Region']==region]['Fatalities'].values\n    score1 = RMSLE(predict_1(region, 1, 1)[:13], actual_confirmed)\n    score2 = RMSLE(predict_2(region, 1, 1)[:13], actual_confirmed)\n    score3 = RMSLE(predict_3(region, 1, 1)[:13], actual_confirmed)\n    score4 = RMSLE(predict_4(region, 1, 1)[:13], actual_confirmed)\n    idx = np.argmin([score1, score2, score3, score4]) + 1\n    model_idxs_confirmed.append(idx)\n    score1 = RMSLE(predict_1(region, 2, 1)[:13], actual_fatalities)\n    score2 = RMSLE(predict_2(region, 2, 1)[:13], actual_fatalities)\n    score3 = RMSLE(predict_3(region, 2, 1)[:13], actual_fatalities)\n    score4 = RMSLE(predict_4(region, 2, 1)[:13], actual_fatalities)\n    idx = np.argmin([score1, score2, score3, score4]) + 1\n    model_idxs_fatalities.append(idx)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_final(region, variable_idx, leaderboard_flag, model_id):\n    if model_id == 1:\n        return predict_1(region, variable_idx, leaderboard_flag)\n    elif model_id == 2:\n        return predict_2(region, variable_idx, leaderboard_flag)\n    elif model_id == 3:\n        return predict_3(region, variable_idx, leaderboard_flag)\n    else:\n        return predict_4(region, variable_idx, leaderboard_flag)\n\ncase_prediction = [predict_final(Unique_Regions[i], 1, 1, model_idxs_confirmed[i]) for i in range(len(Unique_Regions))]\nconfirmed_case_predictions = np.concatenate(case_prediction).astype(int)\ntest['ConfirmedCases'] = confirmed_case_predictions\n\nfatality_prediction = [predict_final(Unique_Regions[i], 2, 1, model_idxs_fatalities[i]) for i in range(len(Unique_Regions))]\nfatality_predictions = np.concatenate(fatality_prediction).astype(int)\ntest['Fatalities'] = fatality_predictions\n\nsubmission = test[['ForecastId', 'ConfirmedCases', 'Fatalities']]\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(20), train[train['Country_Region'] == Unique_Regions[0]]['ConfirmedCases'].values[-20:])\nplt.plot(range(1, 43), submission.iloc[:43, 1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Selecting Stable Regions"},{"metadata":{"trusted":true},"cell_type":"code","source":"for region in Unique_Regions:\n    full_set = pd.merge(train, test)\n    pop = populations[populations['Country_Region'] == region].iloc[0,1]\n    ydata = full_set[full_set['Country_Region'] == region]['ConfirmedCases'].values\n    xdata = np.arange(0, len(ydata), 1)\n    # np.diff(ydata[-7:]).sum() < 8 tells us when a country has little change (< 8 new cases) in the confirmed cases over the past 7 days\n    # you can modify the value 7 to be over a different time span, you can also modify the value 8 to be more or less restrictive\n    ##\n    # ydata[-1:] > 20 tells us when a country has more than a certain number of cases\n    ymax = ydata.max()\n    if np.diff(ydata[-7:]).sum() < int(0.01*ymax) and ydata[-1:] > 20:\n        print(region)\n        plt.plot(ydata/pop)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stable_countries = []\nfor region in Unique_Regions:\n    ydata = train[train['Country_Region'] == region]['ConfirmedCases'].values\n    xdata = np.arange(0, len(ydata), 1)\n    # np.diff(ydata[-7:]).sum() < 8 tells us when a country has little change (< 8 new cases) in the confirmed cases over the past 7 days\n    # you can modify the value 7 to be over a different time span, you can also modify the value 8 to be more or less restrictive\n    ##\n    # ydata[-1:] > 20 tells us when a country has more than a certain number of cases\n    if np.diff(ydata[-7:]).sum() < 8 and ydata[-1:] > 20:\n        stable_countries.append(region)\nstable_countries","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Explore Number of Tests vs Number of Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_test = pd.read_csv('/kaggle/input/covid19testing/tested_worldwide.csv', index_col=0, parse_dates=['Date']).fillna(0).sort_values(by=['Country_Region', 'Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(2, 10):\n#     fig = plt.figure(figsize=(15, 8))\n#     print(covid_test.columns[i])\n#     plt.plot(covid_test[covid_test['Country_Region'] == 'Vietnam'].iloc[:, i])\n# print('Calculated Cumulative')\nplt.plot(covid_test[covid_test['Country_Region'] == 'Vietnam'].iloc[:, -3])\nplt.plot(covid_test[covid_test['Country_Region'] == 'Vietnam'].iloc[:, -3].cummax())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking Distributions of Parameter Guesses"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_model(y):\n    t = range(len(y))\n        # flag=0 --> first pass, flag=1 --> correction\n    x = []\n    middle_loc = int(np.abs(y - y.max()/2).argmin())\n    perct_75_loc = int(np.abs(y - 3*y.max()/4).argmin())\n    try:\n        first_case_loc = np.where(y>1)[0][0]\n    except:\n        first_case_loc = -1\n    if flag==0:\n        x[0] = 1E-5*population\n        x[2] =int(middle_loc)-7\n    else:\n        x[0] = 1E-5*population\n        x[2] = first_case_loc + 21\n    try:\n        x[1] = 20/max(1, perct_75_loc - middle_loc) # estimation of rate of transmission\n    except:\n        x[1] = np.log(2)/2.\n    return x\n    x0 = guess_parameters(y_train, population, 0)\n    res_robust_1 = least_squares(multi_level_logistic, x0, loss='soft_l1', f_scale=0.1, args=(t_train, y_train))\n    fit_1 = multi_level_logistic_model(res_robust_1.x, t_train)\n    residual = y_train - fit_1\n    x0 = guess_parameters(residual, population, 1)\n    res_robust_2 = least_squares(multi_level_logistic, x0, loss='cauchy', f_scale=0.1, args=(t_train, residual))\n    fit_2 = multi_level_logistic_model(res_robust_2.x, t_train)\n    final_forecast = multi_level_logistic_model(res_robust_1.x, t_final) + multi_level_logistic_model(res_robust_2.x, t_final)\n    return final_forecast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\ny = train[train['Country_Region'] == Unique_Regions[0]].iloc[:, 3]\nx = np.arange(len(y))\nplt.plot(x,y, color='r')\nfor i in range(15):\n    plt.plot(x[i*15: (i+1)*16], y[i*15: (i+1)*16])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convexity(y):\n    slope = (y[-1] - y[0])/(len(y) - 1)\n    x = np.arange(len(y))\n    y_hat = x*slope + y[0]\n    return sum(np.abs(y_hat-y)/max(1, y[-1] - y[0]))\n\ndef discrete_convexity_measure(y, m):\n    n = len(y)\n    p = int(n/m)\n    remainder = n%m\n    convexities = [convexity(y[i * m: (i + 1) * m + 1 + (i==(p-1))*remainder]) for i in range(p)]\n    convexity_series = np.concatenate([convexities[i]*np.ones(m + (i==p-1)*remainder) for i in range(p)])\n    return convexity_series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discrete_convexity_measure(y.values, 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = np.zeros(93)\nfor i in range(10, 25):\n    result += np.abs(np.diff(discrete_convexity_measure(y.values, i)))\n\nplt.plot(result)\nplt.show()\nplt.plot(y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(discrete_convexity_measure(y.values, 12))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}